#computes the cliqMat associated with data
cliqMat <- t(cliqMat)
#reduc returns an m x n matrix, so
#needs to be transposed for compatibility with optCliq
cliqFit <- optCliq(cliqMat)
#optimizes the component weights for clique matrix
cliqFit
system.time(cliqFit <- optCliq(cliqMat))
system.time(cliqFit <- optCliq(cliqMat, inner_loops = 500))
cliqFit
system.time(cliqFit <- optCliq(cliqMat, inner_loops = 20))
cliqMat
cliqFit
system.time(cliqFit <- optCliq(cliqMat, inner_loops = 50))
cliqFit
library(MLEcens)
?reduc
library(bivariateCensored)
x <- rexp(20000)
y <- rexp(20000)
system.time(myfit <- ICNPMLE(cbind(x, y) ) )
y <- rexp(20000) + x
system.time(cm <- reduc(cbind(x, y, 0, 1)))
system.time(myfit <- ICNPMLE(cbind(x, y) ) )
system.time(cm <- bivariateNPMLE:::reduc(cbind(x, y, 0, 1)))
system.time(cm <- bivariateCensored:::reduc(cbind(x, y, 0, 1)))
system.time(cm <- MLEcens:::reduc(cbind(x, y, 0, 1)))
x <- rexp(50000)
y <- rexp(50000) + x
system.time(cm <- MLEcens:::reduc(cbind(x, y, 0, 1)))
system.time(myfit <- ICNPMLE(cbind(x, y) ) )
myfit
x <- rexp(5000)
y <- rexp(5000)
x2 <- rexp(5000)
y2 <- rexp(5000) + x2
y <- rexp(5000) + x
system.time(myfit <- ICNPMLE(cbind(x, y, x2, y2) ) )
myfit
library(interval)
initcomputeMLE
library(bivariateCensored)
?ICNPMLE
?reduc
library(bivariateCensored)
?ICNPMLE
?ICNPMLE
?ICNPMLE
library(bivariateCensored)
?ICNPMLE
?ICNPMLE
data(bcos)
data(interval::bcos)
library(interval)
data(bcos)
ICNPMLE(bcos)
library(bivariateCensored)
ICNPMLE(bcos)
bcos
data(bcos)
radOnly <- bcos[bcos$treatment == 'Rad',1:2]
radChem <- bcos[bcos$treatment == 'RadChem', 1:2]
radFit <- ICNPMLE(radOnly)
radChemFit <- ICNPMLE(radChem)
radFit
radChemFit
library(bivariateCensored)
bvData <- simBVCen(n = 2000)
system.time(fit <- ICNPMLE(bvData))
cm <- MLEcens:::reduc(bvData)
cm <- MLEcens:::reduc(bvData, cm = TRUE)
system.time(test1 <- .Call('optCliq', cm, 10^-10,
as.integer(100), as.integer(100),
FALSE))
cm <- MLEcens:::reduc(bvData, cm = TRUE)$cm
system.time(test1 <- .Call('optCliq', cm, 10^-10,
as.integer(100), as.integer(100),
FALSE))
system.time(test1 <- .Call('optCliq', t(cm), 10^-10,
as.integer(100), as.integer(100),
TRUE))
system.time(test2 <- .Call('optCliq', t(cm), 10^-10,
as.integer(100), as.integer(100),
TRUE))
identical(test1, test2)
test1[[2]]
test2[[2]]
test2[[3]]
test1[[3]]
test1[[4]]
test2[[4]]
test3[[4]]
test2[[5]]
test1[[5]]
library(bivariateCensored)
bvData <- simBVCen(n = 2000)
system.time(fit <- ICNPMLE(bvData))
cm <- MLEcens:::reduc(bvData, cm = TRUE)$cm
system.time(test1 <- .Call('optCliq', cm, 10^-10,
as.integer(100), as.integer(100),
FALSE))
system.time(test2 <- .Call('optCliq', t(cm), 10^-10,
as.integer(100), as.integer(100),
TRUE))
system.time(t(cm))
library(bivariateCensored)
bvData <- simBVCen(n = 2000)
system.time(fit <- ICNPMLE(bvData))
cm <- MLEcens:::reduc(bvData, cm = TRUE)$cm
system.time(test1 <- .Call('optCliq', cm, 10^-10,
as.integer(100), as.integer(100),
FALSE))
system.time(test2 <- .Call('optCliq', t(cm), 10^-10,
as.integer(100), as.integer(100),
TRUE))
system.time(test2 <- .Call('optCliq', t(cm), 10^-10,
as.integer(100), as.integer(100),
TRUE))
t_mat <- t(cm)
t_cm <- t(cm)
system.time(test2 <- .Call('optCliq', t_cm, 10^-10,
as.integer(100), as.integer(100),
TRUE))
system.time(test3 <- .Call('optCliq', t_cm, 10^-10,
as.integer(100), as.integer(100),
TRUE))
bvData <- simBVCen(n = 2000)
cm <- MLEcens:::reduc(bvData, cm = TRUE)$cm
system.time(test1 <- .Call('optCliq', cm, 10^-10,
as.integer(100), as.integer(100),
FALSE))
system.time(test2 <- .Call('optCliq', t(cm), 10^-10,
as.integer(100), as.integer(100),
TRUE))
t_cm <- t(cm)
system.time(test3 <- .Call('optCliq', t_cm, 10^-10,
as.integer(100), as.integer(100),
TRUE))
library(bivariateCensored)
system.time(test3 <- .Call('optCliq', t_cm, 10^-10,
as.integer(100), as.integer(100),
TRUE))
system.time(test1 <- .Call('optCliq', cm, 10^-10,
as.integer(100), as.integer(100),
FALSE))
system.time(test2 <- .Call('optCliq', t(cm), 10^-10,
as.integer(100), as.integer(100),
TRUE))
t_cm <- t(cm)
system.time(test3 <- .Call('optCliq', t_cm, 10^-10,
as.integer(100), as.integer(100),
TRUE))
library(bivariateCensored)
system.time(test1 <- .Call('optCliq', cm, 10^-10,
as.integer(100), as.integer(100),
FALSE))
system.time(test3 <- .Call('optCliq', t_cm, 10^-10,
as.integer(100), as.integer(100),
TRUE))
bvData <- simBVCen(n = 4000)
system.time(fit <- ICNPMLE(bvData))
fit
cm <- MLEcens:::reduc(bvData, cm = TRUE)$cm
system.time(test1 <- .Call('optCliq', cm, 10^-10,
as.integer(100), as.integer(100),
FALSE))
t_cm <- t(cm)
system.time(test3 <- .Call('optCliq', t_cm, 10^-10,
as.integer(100), as.integer(100),
TRUE))
test3$llh - test1$llh
ls(test3)
test3[[2]] - test1$[[2]]
test3[[2]] - test1[[2]]
length(test3[[2]])
test3[[2]]
test1[[2]]
library(bivariateCensored)
system.time(test1 <- .Call('optCliq', cm, 10^-10,
as.integer(100), as.integer(100),
FALSE))
t_cm <- t(cm)
system.time(test3 <- .Call('optCliq', t_cm, 10^-10,
as.integer(100), as.integer(100),
TRUE))
test3[[2]] - test1[[2]]
gc()
gc()
simRanks <- function(n = 4, MC = 1000){
posVals <- 1:n
simRanks <- matrix(nrow = MC, ncol = 2)
for(i in 1:MC){
simRanks[i,] <- sample(posVals, 2)
}
return(cor(simRanks[,1], simRanks[,2]))
}
simRanks()
simRanks(5)
simRanks(5, MC = 10000)
simRanks(5, MC = 10000)
simRanks(5, MC = 10000)
simRanks(5, MC = 100000)
install.packages('effsize')
library(effsize)
?cohen.d
myData <- data.frame(grp = rbinom(20, 1, 0.5), y = rnorm(20))
myData
cohen.d(y ~ grp, data = myData)
cohen.d(y ~ factor(grp), data = myData)
library(icenReg)
library(intcox)
library(survival)
library(MLEcens)
MC = 25
NPMLE_ns <- c(500, 5000, 25000)
my_npmle_times <- matrix(nrow = MC, ncol = length(NPMLE_ns))
MLEcens_times <- my_npmle_times
for(i in 1:length(NPMLE_ns)){
this_n <- NPMLE_ns[i]
for(j in 1:MC){
cat(i, ' ', j, ' ')
simdata <- simIC_weib(this_n)
my_npmle_times[j,i] <- system.time(ic_sp(Surv(l, u, type = 'interval2') ~ 0, data = simdata))[1]
simdata <- as.matrix(cbind( simdata[, c('l', 'u')], 1, 2 ))
MLEcens_times[j,i] <- system.time( computeMLE(simdata) )[1]
gc()
}
cat('\n')
}
colMeans(my_npmle_times)
colMeans(MLEcens_times)
testdata <- simIC_weib(n = 500)
library(Icens)
system.time(EMICM(testdata[,c('l', 'u')]))
testdata <- simIC_weib(n = 5000)
system.time(EMICM(testdata[,c('l', 'u')]))
EMICM
EMICMmac
MC = 50
#ns = c(500, 5000, 50000, 500000)
ns = 1000
xs <- 18
prepForSurvReg <- function(data, minVal = 10^-6, maxVal = 10^6){
is0 <- data == 0
data[is0] <- minVal
isInf <- data == Inf
data[isInf] <- maxVal
return(data)
}
for(i in 1:length(ns) ){
this_n = ns[i]
for(j in 1:MC){
cat(i, ' ', j, '  ')
simdata <- simIC_weib(this_n)
simdata <- prepForSurvReg(simdata)
for(k in 1:xs){
simdata[[paste0('var', k)]] <- rnorm(this_n)
}
myTimes[j,i] <- system.time( ic_par(Surv(l, u, type = 'interval2') ~ ., simdata) )[1]
survRegTimes[j,i] <- system.time( survreg(Surv(l, u, type = 'interval2') ~., simdata))[1]
}
cat('\n')
}
myTimes <- matrix(nrow = MC, ncol = length(ns) )
survRegTimes <- myTimes
for(i in 1:length(ns) ){
this_n = ns[i]
for(j in 1:MC){
cat(i, ' ', j, '  ')
simdata <- simIC_weib(this_n)
simdata <- prepForSurvReg(simdata)
for(k in 1:xs){
simdata[[paste0('var', k)]] <- rnorm(this_n)
}
myTimes[j,i] <- system.time( ic_par(Surv(l, u, type = 'interval2') ~ ., simdata) )[1]
survRegTimes[j,i] <- system.time( survreg(Surv(l, u, type = 'interval2') ~., simdata))[1]
}
cat('\n')
}
mean(myTimes)
exp(-exp(2))
exp(-exp(.5))
exp(-exp(0))
exp(0)
exp(-0.5)
exp(-2)
40 * 620
130000 + 130000 * 15 + 24800
130000 + 130000 * .15 + 24800
?ic_sp
?ic_par
nrow = 1000
ncol = 1000
bigMat <- matrix(rbinom(nrow * ncol, size = 1, prob = 0.5), nrow = nrow)
ncol = 5000
nrow = 5000
bigMat <- matrix(rbinom(nrow * ncol, size = 1, prob = 0.5), nrow = nrow)
?lmer
library(lme4)
?"lmer"
install.packages('xml')
install.packages("XML")
library(XML)
URL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
baltrestdata <- xmlTreeParse(URL, useInternal = TRUE)
test <- xmlTreeParse(URL)
?xmlTreeParse
test <- parse(file = URL)
test <- read(file = URL)
test <- read.file(file = URL)
test <- xmlTreeParse(URL, isURL = TRUE)
test <- xmlTreeParse(URL, isURL = TRUE, asText = TRUE)
bigMatrix <- matrix(rbinom(nrow * ncol), nrow = nrow)
bigMatrix <- matrix(rbinom(nrow * ncol, size = 1, prob = 0.5), nrow = nrow)
?clqOpt
?optCliq
?optCliq
library(icenReg)
?optCliq
?ICNPMLE
?optCliq
library(icenReg)
?optCliq
testData <- simBVCen()
icfit <- ICNPMLE(testData)
icfit
testData <- simBVCen(n = 2000)
icfit <- ICNPMLE(testData)
icfit
testData <- simBVCen(n = 3000)
icfit <- ICNPMLE(testData)
icfit
?ICNPMLE
cm <- MLEcens::reduc(testData, cm = TRUE)$cm
testData <- simBVCen(n = 3000)
cm <- MLEcens::reduc(testData, cm = TRUE)$cm
dim(cm)
gc()
testData <- simBVCen(n = 3500)
cm <- MLEcens::reduc(testData, cm = TRUE)$cm
testData <- simBVCen(n = 3500)
cm <- MLEcens::reduc(testData, cm = TRUE)$cm
testData <- simBVCen(n = 3750)
cm <- MLEcens::reduc(testData, cm = TRUE)$cm
myJnk <- optCliq(cm)
myJnk
ls(myJnk)
length(myJnk$pvec)
library(icenReg)
data(essIncData)
fit <- ic_sp(Surv(inc_l, inc_u, type = 'interval2') ~ eduLevel * cntry, data = essIncData)
summary(essIncData)
newdata <- data.frame(cntry = 'Bulgaria', eduLevel = '[16,Inf)')
newdata
getFitEsts(fit, newdata)
newdata <- data.frame(cntry = c('Bulgaria', 'Slovakia'), eduLevel = '[16,Inf)')
newdata
rownames(newdata) <- c('Median income w/Bachelors )
''
'
rownames(newdata) <- c('Median income w/Bachelors in Bulgaria', 'Medain income w/Bachelors in Slovakia')
getFitEsts(fit, newdata)
newdata$cntry[2] = 'Russia'
newdata <- data.frame(cntry = c('Bulgaria', 'Slovakia', 'Russia', 'Poland'), eduLevel = '[16,Inf)')
getFitEsts(fit, newdata)
summary(essIncData)
newdata <- data.frame(cntry = 'Bulgaria', eduLevel = '[0,12)')
getFitEsts(fit, newdata)
?essIncData
data(essIncData)
#A subset of data collected from the European Social Survey
#Income is reported within an interval;
#i.e. income = [3k, 6k) means that subject's income was
#between 3k and 6k Euros
#I think the data is only reported in intervals to remain unidentifiable?
income_fit <- ic_sp(Surv(inc_l, inc_u, type = 'interval2') ~ eduLevel * cntry,
data = essIncData, model = 'po')
#Fits a proportional odds model to the data
#you may recognize that this algorithm is about 100x faster
#than it's competitor (intcox)
#this comparison is complicated by the fact that intcox usually fails
newdata <- data.frame(cntry = 'Bulgaria', eduLevel = '[16, Inf)')
#We want get an estimate of the average yearly income of a Bulgarian with
#at least 4 years of college
estimatedWages <- getFitEsts(fit = income_fit, newdata = newdata, p = 0.5)
estimatedWages
#WOW that's low. No wonder the Bulgarians all want to marry us!
newdata <- data.frame(cntry = 'Bulgaria', eduLevel = '[16,Inf)')
#We want get an estimate of the average yearly income of a Bulgarian with
#at least 4 years of college
estimatedWages <- getFitEsts(fit = income_fit, newdata = newdata, p = 0.5)
estimatedWages
#WOW that's low. No wonder the Bulgarians all want to marry us!
1/0.75
income_fit <- ic_par(Surv(inc_l, inc_u, type = 'interval2') ~ eduLevel * cntry,
data = essIncData, model = 'po')
#Fits a proportional odds model to the data
#you may recognize that this algorithm is about 100x faster
#than it's competitor (intcox)
#this comparison is complicated by the fact that intcox usually fails
newdata <- data.frame(cntry = 'Bulgaria', eduLevel = '[16,Inf)')
#We want get an estimate of the average yearly income of a Bulgarian with
#at least 4 years of college
estimatedWages <- getFitEsts(fit = income_fit, newdata = newdata, p = 0.5)
estimatedWages
#WOW that's low. No wonder the Bulgarians all want to marry us!
#By the way, this data was collected in 2010. I think the exchange rate
#was about 1.4 dollars/euro. So that means in 2010 dollars,
#the median income for a Bulgarian was about
1.4 * estimatedWages
income_fit <- ic_sp(Surv(inc_l, inc_u, type = 'interval2') ~ eduLevel * cntry,
data = essIncData, model = 'po')
#Fits a proportional odds model to the data
#you may recognize that this algorithm is about 100x faster
#than it's competitor (intcox)
#this comparison is complicated by the fact that intcox usually fails
newdata <- data.frame(cntry = 'Bulgaria', eduLevel = '[16,Inf)')
#We want get an estimate of the average yearly income of a Bulgarian with
#at least 4 years of college
estimatedWages <- getFitEsts(fit = income_fit, newdata = newdata, p = 0.5)
estimatedWages
#WOW that's low. No wonder the Bulgarians all want to marry us!
#By the way, this data was collected in 2010. I think the exchange rate
#was about 1.4 dollars/euro. So that means in 2010 dollars,
#the median income for a Bulgarian was about
1.4 * estimatedWages
data(essIncData)
#A subset of data collected from the European Social Survey
#Income is reported within an interval;
#i.e. income = [3k, 6k) means that subject's income was
#between 3k and 6k Euros
#I think the data is only reported in intervals to remain unidentifiable?
income_fit <- ic_sp(Surv(inc_l, inc_u, type = 'interval2') ~ eduLevel * cntry,
data = essIncData, model = 'po')
#Fits a proportional odds model to the data
#you may recognize that this algorithm is about 100x faster
#than it's competitor (intcox)
#this comparison is complicated by the fact that intcox usually fails
newdata <- data.frame(cntry = 'Bulgaria', eduLevel = '[16,Inf)')
#We want get an estimate of the average yearly income of a Bulgarian with
#at least 4 years of college
estimatedWages <- getFitEsts(fit = income_fit, newdata = newdata, p = 0.5)
estimatedWages
#WOW that's low. No wonder the Bulgarians all want to marry us!
#By the way, this data was collected in 2010. I think the exchange rate
#was about 1.4 dollars/euro. So that means in 2010 dollars,
#the median income for a Bulgarian was about
1.4 * estimatedWages
?optCliq
rm(bigMat)
rm(cm)
rm(bigMatrix)
gc()
gc()
library(icenReg)
?optCliq
library(icenReg)
?optCliq
1.4 * estimatedWages * 2
pwd()
setwd("~/icenRegShortCut/Code/icenReg/man")
f <-
'ICNPMLE/Rd'
tools::showNonASCII(f)
tools::showNonASCII(readLines(f) )
f
f <-'ICNPMLE.Rd'
tools::showNonASCII(readLines(f) )
tools::showNonASCII(readLines(f) )
tools::showNonASCII(readLines(f) )
tools::showNonASCII(readLines(f) )
tools::showNonASCII(readLines(f) )
library(icenReg)
?ICNPMLE
?optCliq
?ICNPMLE
samp_mlat_.5 <- power.t.test(mice_lat_con_d * .5, power = 0.8)
mice_lat_con_d <- 0.97
mice_dist_con_d <- 0.88
hum_dist_con_d <- 0.75
samp_mlat_.5 <- power.t.test(mice_lat_con_d * .5, power = 0.8)
mice_lat_con_d
power.t.test(mice_lat_con_d, power = 0.8)
samp_mlat_.5 <- power.t.test(delta = mice_lat_con_d * .5, power = 0.8)
samp_mdist.5 <- power.t.test(delta = mice_dist_con_d *.5, power = 0.8)
samp_mlat.5 <- power.t.test(delta = mice_lat_con_d * .5, power = 0.8)
samp_mlat.25 <- power.t.test(delta = mice_lat_con_d * .25, power = .8)
#Power for distance " "
samp_mdist.5 <- power.t.test(delta = mice_dist_con_d *.5, power = 0.8)
samp_mdist.25 <- power.t.test(delta = mice_dist_con_d *.25, power = 0.8)
#Power for humans distance ""
samp_hdist.5 <- power.t.test(delta = hum_dist_con_d, power = 0.8)
samp_hdist.25 <- power.t.test(delta = hum_dist_con_d, power = 0.8)
samp_hdist.5
samp_mlat.5 <- power.t.test(delta = mice_lat_con_d * .5, power = 0.8)
samp_mlat.25 <- power.t.test(delta = mice_lat_con_d * .25, power = .8)
#Power for distance " "
samp_mdist.5 <- power.t.test(delta = mice_dist_con_d *.5, power = 0.8)
samp_mdist.25 <- power.t.test(delta = mice_dist_con_d *.25, power = 0.8)
#Power for humans distance ""
samp_hdist.5 <- power.t.test(delta = hum_dist_con_d, power = 0.8)
samp_hdist.25 <- power.t.test(delta = hum_dist_con_d, power = 0.8)
samp_hdist.5
samp_hdist.5 <- power.t.test(delta = hum_dist_con_d * .5, power = 0.8)
samp_hdist.25 <- power.t.test(delta = hum_dist_con_d *0.25, power = 0.8)
samp_hdist.5
samp_mlat.5
samp_mlat.25
samp_mdist.5
samp_mdist.25
samp_hdist.5
samp_hdist.25
